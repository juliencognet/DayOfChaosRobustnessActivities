# Day Of Chaos - Activit√©s acc√©l√©ratrices
Les activit√©s suivantes vous sont propos√©es afin d'acc√©l√©rer vos chances de succ√®s. Elles vous permettront d'augmenter vos chances de succ√®s au sein du Day Of Chaos, mais aussi de d√©couvrir les actions qui peuvent √™tre r√©alis√©es par des administrateurs syst√®me afin de rendre un syst√®me plus r√©silient et facile √† maintenir.

## A. Ajouter des paires de cl√©s ssh 


### A1. Pourquoi le faire ?
- Faciliter un acc√®s s√©curis√© sans mot de passe entre diff√©rentes machines. 
- Automatiser des t√¢ches administratives n√©cessitant des connexions SSH. 
- R√©duire les risques li√©s au partage ou √† l'utilisation de mots de passe. 

Int√©r√™t pour le jeu : üü¢üü¢üü¢üü¢‚ö™ - Facilit√© de mise en oeuvre : üü¢üü¢üü¢üü¢‚ö™

### A2. Le principe
L'authentification avec cl√© SSH repose sur la cryptographie asym√©trique pour s√©curiser l'acc√®s sans utiliser de mot de passe. Voici le fonctionnement d√©taill√© :

1. **G√©n√©ration de la paire de cl√©s :**

-   Vous g√©n√©rez une paire de cl√©s (g√©n√©ralement stock√©e dans `~/.ssh` :
    -   **Cl√© priv√©e** : Conserv√©e sur votre machine, secr√®te. Nomm√©e par d√©faut `id_rsa.pub`
    -   **Cl√© publique** : Transmise au serveur. Nomm√©e par d√©faut `id_rsa`

2. **Ajout de la cl√© publique sur le serveur :**

-   La cl√© publique est ajout√©e au fichier `~/.ssh/authorized_keys` du serveur.
-   Ce fichier contient les cl√©s autoris√©es √† se connecter.

3. **Processus d'authentification :**

-   Vous initiez une connexion SSH au serveur.
-   Le serveur envoie un **challenge chiffr√©** (une sorte de message crypt√©) √† votre machine.
-   Votre client SSH utilise la **cl√© priv√©e** pour d√©chiffrer ce message.
-   Si le d√©chiffrement est correct, le serveur accorde l'acc√®s.

4. **S√©curisation :**

-   La cl√© priv√©e ne quitte jamais votre machine.
-   Le serveur ne stocke que la cl√© publique, qui ne permet pas de reconstruire la cl√© priv√©e.

Cette m√©thode √©limine le besoin d'un mot de passe et renforce la s√©curit√© en prot√©geant contre les attaques par interception.

### Comment le faire ?
1. G√©n√©rer une paire de cl√©s SSH :

` ssh-keygen -t rsa -b 4096 -C "votre_email@example.com" `

2. Copier la cl√© publique vers une autre machine: 

` ssh-copy-id utilisateur@adresse_ip`



## B. Mettre en ≈ìuvre des services Linux

### B1. Pourquoi le faire ?
Mettre en ≈ìuvre un service Linux offre plusieurs avantages par rapport √† un simple script shell de d√©marrage :

1. **Gestion avanc√©e du cycle de vie**

-   Les services Linux, g√©r√©s par des outils comme `systemd`, permettent de **d√©marrer**, **arr√™ter**, **red√©marrer** ou **recharger** les processus de mani√®re standardis√©e.
-   Ils offrent une meilleure gestion des d√©pendances entre services (ex. : d√©marrer un service uniquement apr√®s un autre).

2. **Supervision et r√©silience**

-   Les services peuvent √™tre configur√©s pour red√©marrer automatiquement en cas de plantage.
-   Les outils comme `systemctl` fournissent un suivi en temps r√©el de l‚Äô√©tat des services.

3. **Ex√©cution au d√©marrage**

-   Les services peuvent √™tre configur√©s pour s'ex√©cuter automatiquement au d√©marrage du syst√®me, avec des priorit√©s d√©finies.

4. **Uniformit√© et maintenabilit√©**

-   Les services suivent une convention commune (`/etc/systemd/system/`), rendant leur gestion plus simple pour les administrateurs.
-   Les scripts de d√©marrage manuels, en revanche, peuvent √™tre dispers√©s et difficiles √† maintenir.

5. **S√©curit√©**

-   Les services Linux permettent de d√©finir des utilisateurs sp√©cifiques, des limites de ressources et des environnements isol√©s pour r√©duire les risques li√©s √† des processus mal configur√©s.

**En r√©sum√©** :

Un service Linux est plus robuste, maintenable et s√©curis√©, surtout pour des processus critiques ou de longue dur√©e, tandis qu‚Äôun script shell peut suffire pour des t√¢ches simples et ponctuelles.

Int√©r√™t pour le jeu : üü¢üü¢üü¢üü¢‚ö™ - Facilit√© de mise en ≈ìuvre : üü¢üü¢üü¢‚ö™‚ö™


### B2. Comment le faire ?
Voici les √©tapes pour convertir un script shell en service g√©r√© par `systemd` :

1. **Cr√©er le script shell**

Assurez-vous que votre script shell fonctionne correctement et est ex√©cutable. Par exemple :

    #!/bin/bash
    echo "Mon service est d√©marr√© !" >> /var/log/mon_service.log
    # Commandes √† ex√©cuter

Enregistrez-le, par exemple, sous `/usr/local/bin/mon_script.sh` et rendez-le ex√©cutable :

    chmod +x /usr/local/bin/mon_script.sh

2. **Cr√©er un fichier de service systemd**

Cr√©ez un fichier de configuration dans `/etc/systemd/system/mon_service.service` :

    [Unit]
    Description=Mon Service Personnalis√©
    After=network.target  # D√©marre apr√®s le r√©seau
    
    [Service]
    ExecStart=/usr/local/bin/mon_script.sh  # Commande pour lancer le script
    Restart=always                          # Red√©marre en cas d'√©chec
    User=mon_utilisateur                    # (Optionnel) D√©finit l'utilisateur qui ex√©cute le service
    WorkingDirectory=/usr/local/bin         # (Optionnel) R√©pertoire de travail
    Environment="VAR1=valeur1" "VAR2=valeur2"  # (Optionnel) Variables d'environnement
    
    [Install]
    WantedBy=multi-user.target

3. **Activer et d√©marrer le service**

Rechargez les configurations de `systemd` :

    sudo systemctl daemon-reload

Activez le service pour qu‚Äôil d√©marre au d√©marrage du syst√®me :

    sudo systemctl enable mon_service
D√©marrez le service imm√©diatement :

    sudo systemctl start mon_service

4. **V√©rifier l‚Äô√©tat du service**

V√©rifiez si le service fonctionne correctement :

    sudo systemctl status mon_service
Consultez les logs du service :

    journalctl -u mon_service

5. **Tester le red√©marrage automatique (optionnel)**

Simulez une panne en arr√™tant manuellement le processus ou en utilisant `kill`. Le service doit red√©marrer automatiquement si `Restart=always` est configur√©.

Avec ces √©tapes, votre script shell est d√©sormais g√©r√© comme un service syst√®me robuste et maintenable.


## C. Centraliser les logs

### C1. Pourquoi le faire ?
-   Simplifier l'analyse des √©v√©nements en rassemblant les journaux de plusieurs machines ou applications.
-   D√©tecter et r√©soudre rapidement des anomalies gr√¢ce √† une vision consolid√©e.
-   Respecter les bonnes pratiques de gestion et de conformit√© en mati√®re de logs.

Int√©r√™t pour le jeu : üü¢üü¢üü¢üü¢üü¢ - Facilit√© de mise en oeuvre : üü¢‚ö™‚ö™‚ö™‚ö™

### C2. Comment le faire ?
Une solution simple et moderne pour centraliser les logs d'un syst√®me consiste √† utiliser un syst√®me d'agr√©gation et d'interrogation de logs tel que **Grafana Loki** combin√© √† un agent de collecte et d'envoi de logs tel que **Promtail**. 

#### C2.1. Installation de Grafana Loki
Voici un fichier `docker-compose.yml` pour installer **Grafana** et **Loki** avec **Docker Compose** :

```yaml
version: "3.8"

services:
  loki:
    image: grafana/loki:latest
    container_name: loki
    ports:
      - "3100:3100"
    volumes:
      - ./loki-config.yaml:/etc/loki/local-config.yaml
    command: -config.file=/etc/loki/local-config.yaml

  grafana:
    image: grafana/grafana:latest
    container_name: grafana
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_USER=admin
      - GF_SECURITY_ADMIN_PASSWORD=admin
    depends_on:
      - loki

volumes:
  loki_data:

```


1. **Cr√©er la configuration pour Loki**

Cr√©ez un fichier nomm√© `loki-config.yaml` dans le m√™me dossier que le fichier `docker-compose.yml` :

```yaml
auth_enabled: false

server:
  http_listen_port: 3100

ingester:
  lifecycler:
    ring:
      kvstore:
        store: inmemory
      replication_factor: 1
  chunk_idle_period: 5m
  chunk_retain_period: 30s
  max_transfer_retries: 0

schema_config:
  configs:
    - from: 2020-10-24
      store: boltdb-shipper
      object_store: filesystem
      schema: v11
      index:
        prefix: index_
        period: 24h

storage_config:
  boltdb_shipper:
    active_index_directory: /tmp/loki/index
    cache_location: /tmp/loki/cache
    shared_store: filesystem
  filesystem:
    directory: /tmp/loki/chunks

limits_config:
  enforce_metric_name: false
  reject_old_samples: true
  reject_old_samples_max_age: 168h

chunk_store_config:
  max_look_back_period: 0s

table_manager:
  retention_deletes_enabled: false
  retention_period: 0s

```

2. **D√©marrer les conteneurs**

Lancez Docker Compose :

```bash
docker-compose up -d
```


3. **Acc√©der √† Grafana**

-   Acc√©dez √† Grafana √† l‚Äôadresse : `http://localhost:3000`.
-   Connectez-vous avec les identifiants par d√©faut (`admin` / `admin`) ou ceux d√©finis dans le fichier Compose.

4. **Configurer Loki comme source de donn√©es dans Grafana**

	1.  Dans Grafana, allez dans **Configuration > Data Sources**.
	2.  Ajoutez une nouvelle source de donn√©es avec le type **Loki**.
	3.  Configurez l'URL comme `http://loki:3100`.
	4.  Enregistrez et testez la connexion.

5. **Visualiser les logs**

-   Dans Grafana, utilisez **Explore** pour rechercher les logs.
-   Configurez vos applications ou services pour envoyer des logs √† Loki via des agents comme  **Promtail**.

#### C2.2. Installation de Promtail
Promtail est un agent l√©ger et simple qui lit les fichiers journaux (m√™me en texte brut) et les envoie directement √† Loki. Il est facile √† configurer et ne n√©cessite aucune modification des logs existants.

Voici comment installer et configurer **Promtail** sur un serveur en utilisant **Docker** pour envoyer des logs √† Loki.

1. **Cr√©er un fichier de configuration Promtail**

Cr√©ez un fichier de configuration `promtail-config.yaml` sur votre machine, par exemple dans `/etc/promtail/config.yml`. Ce fichier d√©finit comment Promtail collectera et enverra les logs √† Loki.

Exemple de configuration :

```yaml
server:
  http_listen_port: 9080
  grpc_listen_port: 0

clients:
  - url: http://<adresse_du_serveur_loki>:3100/loki/api/v1/push

positions:
  filename: /tmp/positions.yaml

scrape_configs:
  - job_name: "system-logs"
    static_configs:
      - targets:
          - localhost
        labels:
          job: varlogs
          host: my-machine
          __path__: /var/log/*.log

```

-   **`<adresse_du_serveur_loki>`** : Remplacez par l‚Äôadresse IP ou le domaine de votre serveur Loki.
-   **`__path__`** : Sp√©cifie les fichiers logs √† lire (ici tous les logs dans `/var/log/`).
-   **Labels** : Vous pouvez ajouter des labels comme `host` pour identifier la machine.



2. **Lancer Promtail avec Docker**

Dans le m√™me r√©pertoire que votre fichier de configuration `promtail-config.yaml`, ex√©cutez la commande suivante pour d√©marrer Promtail dans un conteneur Docker.

```bash
docker run -d \
  --name promtail \
  --restart unless-stopped \
  -v /etc/promtail/config.yml:/etc/promtail/config.yml \
  -v /var/log:/var/log \
  -v /tmp:/tmp \
  grafana/promtail:latest \
  -config.file=/etc/promtail/config.yml

```

-   **`-v /etc/promtail/config.yml:/etc/promtail/config.yml`** : Montez le fichier de configuration Promtail dans le conteneur.
-   **`-v /var/log:/var/log`** : Montez les logs du syst√®me pour que Promtail puisse les lire.
-   **`-v /tmp:/tmp`** : Montez `/tmp` pour stocker les fichiers de positions.

----------

3. **V√©rification et suivi**

Pour v√©rifier que Promtail fonctionne correctement, vous pouvez consulter les logs du conteneur Docker :

```bash
docker logs -f promtail

```

Assurez-vous que Promtail envoie les logs au serveur Loki sans erreur.

----------

**4. Acc√©der √† Grafana**

Acc√©dez √† Grafana (exemple : `http://<adresse_de_votre_serveur>:3000`), et configurez **Loki** comme source de donn√©es :

1.  Allez dans **Configuration > Data Sources**.
2.  S√©lectionnez **Loki** comme type de source de donn√©es.
3.  Mettez l'URL de votre serveur Loki (exemple : `http://<adresse_du_serveur_loki>:3100`).

----------

**5. Visualisation des logs dans Grafana**

-   Dans Grafana, allez dans **Explore**.
-   S√©lectionnez votre source de donn√©es Loki et explorez les logs envoy√©s depuis Promtail.

----------


### **R√©sum√© :**

1.  **Fichier de configuration** : Cr√©ez un fichier `promtail-config.yaml`.
2.  **Docker** : Lancez Promtail en utilisant un conteneur Docker.
3.  **Grafana** : Connectez Grafana √† Loki pour visualiser les logs centralis√©s.

Cette solution avec Docker est simple et rapide, et vous permet de centraliser les logs sur Loki sans n√©cessiter d'installation complexe sur la machine.
